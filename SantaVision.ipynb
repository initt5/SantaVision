{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **CNN model for recognizing Christmas Eve dishes**\n",
        "\n",
        "*Hackaton - Noc Sztucznej Inteligencji*\n",
        "\n",
        "**Authors:**\n",
        "\n",
        "Jakub Zdancewicz\n",
        "\n",
        "Wiktor Niedźwiedzki"
      ],
      "metadata": {
        "id": "a5tXPqu8dWsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model trenowany na google colab\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ll00spaAP4D",
        "outputId": "aaa93d35-ad93-4d2e-a04b-d7deef52a610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchaudio torchvision torchtext torchdata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJHGBTch8JLJ",
        "outputId": "083b6d7c-c0e2-464c-c5ba-89930db44c2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.2.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wczytanie własnego data setu"
      ],
      "metadata": {
        "id": "orN_-7F2c1D0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf /content/data\n",
        "# !unzip -qq \"data.zip\""
      ],
      "metadata": {
        "id": "BMmPwo9Hao92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Uczenie modelu"
      ],
      "metadata": {
        "id": "duMwwfk6cph-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.set_device(torch.device(\"cuda:0\"))"
      ],
      "metadata": {
        "id": "ELYD6PzZ71On"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "lr = 0.0001 # learning rate\n",
        "batch_size = 128\n",
        "num_epochs = 11\n",
        "lr_decay = 0.1 # decay rate\n",
        "num_classes = 8\n",
        "\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    random.seed(seed)\n",
        "set_seed(42)"
      ],
      "metadata": {
        "id": "IxkgHwmm-RDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels = {\n",
        "    'barszcz czerwony': 1,\n",
        "    'bigos': 2,\n",
        "    'kutia': 3,\n",
        "    'makowiec': 4,\n",
        "    'pierniki': 5,\n",
        "    'pierogi': 6,\n",
        "    'sernik': 7,\n",
        "    'zupa grzybowa': 8\n",
        "}"
      ],
      "metadata": {
        "id": "f38FTemCG0eO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.Resize((254, 254)), # Resnet needs 224 x 224 images\n",
        "            transforms.ToTensor(),\n",
        "            #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize((254, 254)),\n",
        "            transforms.ToTensor(),\n",
        "            #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ]),\n",
        "        'test': transforms.Compose([\n",
        "            transforms.Resize((254, 254)),\n",
        "            transforms.ToTensor(),\n",
        "            #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ]),\n",
        "}"
      ],
      "metadata": {
        "id": "OFeihIwX9V4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(file_path, output_dir, validation_split=0.2, test_split=0.1, batch_size=32):\n",
        "    # create output directory if doesn't exist\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # create train, val, test folders\n",
        "    train_dir = os.path.join(output_dir, 'train')\n",
        "    val_dir = os.path.join(output_dir, 'val')\n",
        "    test_dir = os.path.join(output_dir, 'test')\n",
        "\n",
        "    for subset_dir in [train_dir, val_dir, test_dir]:\n",
        "        if not os.path.exists(subset_dir):\n",
        "            os.makedirs(subset_dir)\n",
        "\n",
        "\n",
        "    # split images into train, val and test sets\n",
        "    for class_name in os.listdir(file_path):\n",
        "        class_path = os.path.join(file_path, class_name)\n",
        "        if not os.path.isdir(class_path):\n",
        "            continue\n",
        "\n",
        "        images = os.listdir(class_path)\n",
        "\n",
        "\n",
        "        train_images, temp_images = train_test_split(images, test_size=(validation_split + test_split), random_state=42)\n",
        "        val_images, test_images = train_test_split(temp_images, test_size=test_split / (validation_split + test_split), random_state=42)\n",
        "\n",
        "        for image in train_images + val_images + test_images:\n",
        "            src = os.path.join(class_path, image)\n",
        "            try:\n",
        "                with Image.open(src) as img:\n",
        "                    # Convert to RGB to prevent PIL errors\n",
        "                    img = img.convert('RGBA' if img.mode == 'P' and 'transparency' in img.info else 'RGB')\n",
        "\n",
        "                    label = class_labels.get(class_name, None)\n",
        "\n",
        "                    # put images in correct folders\n",
        "                    if image in train_images:\n",
        "                        dst_dir = os.path.join(train_dir, str(label))\n",
        "                    elif image in val_images:\n",
        "                        dst_dir = os.path.join(val_dir, str(label))\n",
        "                    else:\n",
        "                        dst_dir = os.path.join(test_dir, str(label))\n",
        "\n",
        "                    os.makedirs(dst_dir, exist_ok=True)\n",
        "                    dst = os.path.join(dst_dir, image)\n",
        "\n",
        "                    img.save(dst)\n",
        "            except Exception as e:\n",
        "                print(f\"Błąd podczas przetwarzania obrazu '{image}': {e}\") # Few images are weird\n",
        "\n",
        "    # ImageFolder dataloader\n",
        "    image_datasets = {\n",
        "        'train': datasets.ImageFolder(train_dir, data_transforms['train']),\n",
        "        'val': datasets.ImageFolder(val_dir, data_transforms['val']),\n",
        "        'test': datasets.ImageFolder(test_dir, data_transforms['test']),\n",
        "    }\n",
        "\n",
        "    # create data loaders\n",
        "    dataloaders = {\n",
        "        'train': DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True, num_workers=2),\n",
        "        'val': DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=False, num_workers=2),\n",
        "        'test': DataLoader(image_datasets['test'], batch_size=batch_size, shuffle=False, num_workers=2),\n",
        "    }\n",
        "\n",
        "    return image_datasets, dataloaders"
      ],
      "metadata": {
        "id": "MjHTMQsJAHHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/m"
      ],
      "metadata": {
        "id": "Yc2S7IJ1cUUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "database_path = \"/content/data\"\n",
        "splitted_data_path = \"/content/m\"\n",
        "image_datasets, dataloaders = prepare_data(database_path, splitted_data_path, validation_split=0.2, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkvwVqDAJjBe",
        "outputId": "1cbee326-1f44-41a6-ff87-dc0b3060316e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Błąd podczas przetwarzania obrazu 'pierniki_118.jpg': cannot write mode RGBA as JPEG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloaders, image_datasets, device, loss_fn, optimizer, lr_scheduler=None, num_epochs=10):\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        print(f'Epoch {epoch}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # lr decay\n",
        "        if lr_scheduler:\n",
        "            lr_scheduler(optimizer, epoch)\n",
        "\n",
        "        # train mode\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        # Iterate through batches\n",
        "        for inputs, labels in dataloaders['train']:\n",
        "\n",
        "            # CUDA things (or cpu if CUDA is unavailable)\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # clean gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(True):\n",
        "                # forward pass\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = loss_fn(outputs, labels)\n",
        "\n",
        "                # backward pass\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            # get total loss for a batch\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        epoch_loss = running_loss / len(image_datasets['train'])\n",
        "        epoch_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "        print(f'Train Loss: {epoch_loss:.4f} F1-score: {epoch_f1:.4f}')\n",
        "\n",
        "        model.eval()\n",
        "        running_loss = 0.0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        # Val loss\n",
        "        for inputs, labels in dataloaders['val']:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # prevent from calculating gradient\n",
        "            with torch.set_grad_enabled(False):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = loss_fn(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        epoch_loss = running_loss / len(image_datasets['val'])\n",
        "        epoch_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "        print(f'Validation Loss: {epoch_loss:.4f} F1-score: {epoch_f1:.4f}')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "jU9b7von99lR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def exp_lr_scheduler(optimizer, epoch, init_lr=0.0001, lr_decay_epoch=5, decay_weight=0.1):\n",
        "    # Calculate lr for current epoch\n",
        "    lr = init_lr * (decay_weight**(epoch // lr_decay_epoch))\n",
        "\n",
        "    if epoch % lr_decay_epoch == 0:\n",
        "        print('LR is set to {:.6f}'.format(lr))\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "    return optimizer"
      ],
      "metadata": {
        "id": "kBO42BXSCRGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finetune ResNet\n",
        "model_ft = models.resnet50(weights='DEFAULT')\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "# Loss\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "if device.type == 'cuda':\n",
        "    criterion = loss_fn.cuda()\n",
        "    model_ft = model_ft.cuda()\n",
        "\n",
        "# Optimizer\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=lr)\n",
        "\n",
        "model_ft = train_model(model_ft, dataloaders, image_datasets, device, loss_fn, optimizer_ft,\n",
        "                       lambda opt, epoch: exp_lr_scheduler(opt, epoch, init_lr=lr, lr_decay_epoch=5, decay_weight=lr_decay),\n",
        "                       num_epochs=num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFBAgpMJPueE",
        "outputId": "c6daf4d8-a712-4e85-fc97-fcd2f5c96216"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/11\n",
            "----------\n",
            "Train Loss: 1.7747 F1-score: 0.5877\n",
            "Validation Loss: 1.1571 F1-score: 0.8634\n",
            "Epoch 2/11\n",
            "----------\n",
            "Train Loss: 0.6700 F1-score: 0.9540\n",
            "Validation Loss: 0.2266 F1-score: 0.9542\n",
            "Epoch 3/11\n",
            "----------\n",
            "Train Loss: 0.1521 F1-score: 0.9809\n",
            "Validation Loss: 0.0979 F1-score: 0.9687\n",
            "Epoch 4/11\n",
            "----------\n",
            "Train Loss: 0.0443 F1-score: 0.9922\n",
            "Validation Loss: 0.0832 F1-score: 0.9750\n",
            "Epoch 5/11\n",
            "----------\n",
            "LR is set to 0.000010\n",
            "Train Loss: 0.0191 F1-score: 0.9988\n",
            "Validation Loss: 0.0826 F1-score: 0.9791\n",
            "Epoch 6/11\n",
            "----------\n",
            "Train Loss: 0.0222 F1-score: 0.9976\n",
            "Validation Loss: 0.0924 F1-score: 0.9771\n",
            "Epoch 7/11\n",
            "----------\n",
            "Train Loss: 0.0174 F1-score: 0.9994\n",
            "Validation Loss: 0.0919 F1-score: 0.9708\n",
            "Epoch 8/11\n",
            "----------\n",
            "Train Loss: 0.0183 F1-score: 0.9982\n",
            "Validation Loss: 0.0924 F1-score: 0.9687\n",
            "Epoch 9/11\n",
            "----------\n",
            "Train Loss: 0.0163 F1-score: 0.9994\n",
            "Validation Loss: 0.0792 F1-score: 0.9750\n",
            "Epoch 10/11\n",
            "----------\n",
            "LR is set to 0.000001\n",
            "Train Loss: 0.0155 F1-score: 0.9988\n",
            "Validation Loss: 0.0842 F1-score: 0.9708\n",
            "Epoch 11/11\n",
            "----------\n",
            "Train Loss: 0.0192 F1-score: 0.9982\n",
            "Validation Loss: 0.0806 F1-score: 0.9750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get test set loss\n",
        "model_ft.eval()\n",
        "\n",
        "running_loss = 0.0\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "for inputs, labels in dataloaders['test']:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model_ft(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "    running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    all_preds.extend(preds.cpu().numpy())\n",
        "    all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "epoch_loss = running_loss / len(image_datasets['test'])\n",
        "epoch_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "\n",
        "print(f'Test Loss: {epoch_loss:.4f} F1-score: {epoch_f1:.4f}')"
      ],
      "metadata": {
        "id": "7uwN07l5cR8z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d2d27b4-5353-439f-b932-521a22ea37b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0921 F1-score: 0.9835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_ft.state_dict(), \"model_weights.pth\")"
      ],
      "metadata": {
        "id": "9GO0CJIjORho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testowanie modelu"
      ],
      "metadata": {
        "id": "fJVVK1GZch7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wczytanie modelu\n",
        "num_classes = 8\n",
        "model_ft = models.resnet50(weights=None)\n",
        "\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_ft.load_state_dict(torch.load(\"model_weights.pth\", map_location=torch.device(device)))\n",
        "\n",
        "print(\"Model loaded successfully!\")\n",
        "\n",
        "model_ft = model_ft.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRaUMYdsOwhJ",
        "outputId": "a2b7e790-5e3b-4d08-a279-4c7b8b235a80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-a826e2bdde9f>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_ft.load_state_dict(torch.load(\"model_weights.pth\", map_location=torch.device(device)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model image classification\n",
        "def classify_image(model, image_path, class_labels, device):\n",
        "\n",
        "    # transform input Image\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    # Changing classes indexes in train_model() causes CUDA errors so changing them during inference\n",
        "    try:\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "        input_tensor = transform(image).unsqueeze(0) # Add batch dimension\n",
        "\n",
        "        input_tensor = input_tensor.to(device)\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_tensor)\n",
        "            _, predicted_class = torch.max(outputs, 1)\n",
        "\n",
        "        class_index = predicted_class.item()\n",
        "        return predicted_class.item() + 1\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image '{image_path}': {e}\")\n",
        "        return None\n",
        "\n",
        "class_labels = {\n",
        "    'barszcz czerwony': 1,\n",
        "    'bigos': 2,\n",
        "    'kutia': 3,\n",
        "    'makowiec': 4,\n",
        "    'pierniki': 5,\n",
        "    'pierogi': 6,\n",
        "    'sernik': 7,\n",
        "    'zupa grzybowa': 8\n",
        "}"
      ],
      "metadata": {
        "id": "PPzWk2EFUiDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/test\n",
        "!unzip -qq \"test.zip\""
      ],
      "metadata": {
        "id": "mB15CspgZhy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = \"/content/test/\"\n",
        "files = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, file))]\n",
        "\n",
        "class_labels_reverse = {v: k for k, v in class_labels.items()}\n",
        "\n",
        "for image_path in files:\n",
        "    file_name = os.path.basename(image_path)\n",
        "    predicted_label_index = classify_image(model_ft, image_path, class_labels, device)\n",
        "    predicted_label = class_labels_reverse.get(predicted_label_index, \"Unknown\")\n",
        "    print(f\"{file_name} -> {predicted_label}\")"
      ],
      "metadata": {
        "id": "0MImwoa2V8Ki",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba56fb7-f274-4a89-9ac5-43e4d2064511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "zupa z grzybami_20.jpg -> zupa grzybowa\n",
            "zupa barszcz_2.jpg -> zupa grzybowa\n",
            "zupa z grzybami_13.jpg -> zupa grzybowa\n",
            "polskie pierogi_6.jpg -> pierogi\n",
            "sernik z rodzynkami_9.jpg -> sernik\n",
            "zupa barszcz_21.jpg -> barszcz czerwony\n",
            "super bigos_5.jpg -> bigos\n",
            "super bigos_20.jpg -> bigos\n",
            "super bigos_11.jpg -> bigos\n",
            "ciasto makowe_5.jpg -> makowiec\n",
            "sernik z rodzynkami_6.jpg -> sernik\n",
            "zupa z grzybami_5.jpg -> zupa grzybowa\n",
            "ciasto makowe_14.jpg -> makowiec\n",
            "ciasto makowe_8.jpg -> makowiec\n",
            "sernik z rodzynkami_11.jpg -> sernik\n",
            "ciasto makowe_18.jpg -> makowiec\n",
            "zupa z grzybami_10.jpg -> zupa grzybowa\n",
            "sernik z rodzynkami_4.jpg -> sernik\n",
            "super bigos_19.jpg -> bigos\n",
            "polskie pierogi_21.jpg -> pierogi\n",
            "zupa barszcz_17.jpg -> barszcz czerwony\n",
            "polskie pierogi_10.jpg -> pierogi\n",
            "zupa z grzybami_4.jpg -> zupa grzybowa\n",
            "polskie pierogi_11.jpg -> pierogi\n",
            "super bigos_6.jpg -> bigos\n",
            "polskie pierogi_23.jpg -> pierogi\n",
            "ciasto makowe_21.jpg -> makowiec\n",
            "super bigos_16.jpg -> bigos\n",
            "zupa z grzybami_8.jpg -> zupa grzybowa\n",
            "polskie pierogi_17.jpg -> pierogi\n",
            "zupa z grzybami_2.jpg -> zupa grzybowa\n",
            "ciasto makowe_4.jpg -> makowiec\n",
            "zupa barszcz_20.jpg -> barszcz czerwony\n",
            "sernik z rodzynkami_18.jpg -> sernik\n",
            "zupa z grzybami_3.jpg -> zupa grzybowa\n",
            "super bigos_3.jpg -> bigos\n",
            "zupa barszcz_11.jpg -> barszcz czerwony\n",
            "ciasto makowe_2.jpg -> sernik\n",
            "zupa barszcz_13.jpg -> barszcz czerwony\n",
            "ciasto makowe_16.jpg -> sernik\n",
            "super bigos_14.jpg -> bigos\n",
            "sernik z rodzynkami_8.jpg -> sernik\n",
            "zupa z grzybami_19.jpg -> zupa grzybowa\n",
            "polskie pierogi_3.jpg -> pierogi\n",
            "sernik z rodzynkami_16.jpg -> sernik\n",
            "zupa z grzybami_18.jpg -> zupa grzybowa\n",
            "zupa z grzybami_12.jpg -> zupa grzybowa\n",
            "sernik z rodzynkami_20.jpg -> sernik\n",
            "polskie pierogi_16.jpg -> pierogi\n",
            "zupa barszcz_9.jpg -> barszcz czerwony\n",
            "super bigos_7.jpg -> bigos\n",
            "super bigos_4.jpg -> bigos\n",
            "ciasto makowe_12.jpg -> makowiec\n",
            "super bigos_17.jpg -> bigos\n",
            "polskie pierogi_8.jpg -> pierogi\n",
            "zupa barszcz_16.jpg -> barszcz czerwony\n",
            "super bigos_18.jpg -> bigos\n",
            "zupa barszcz_3.jpg -> zupa grzybowa\n",
            "zupa z grzybami_7.jpg -> zupa grzybowa\n",
            "zupa barszcz_14.jpg -> barszcz czerwony\n",
            "sernik z rodzynkami_10.jpg -> sernik\n",
            "ciasto makowe_17.jpg -> sernik\n",
            "zupa z grzybami_6.jpg -> zupa grzybowa\n",
            "sernik z rodzynkami_19.jpg -> sernik\n",
            "ciasto makowe_6.jpg -> makowiec\n",
            "ciasto makowe_3.jpg -> makowiec\n",
            "sernik z rodzynkami_7.jpg -> sernik\n",
            "zupa barszcz_18.jpg -> barszcz czerwony\n",
            "zupa barszcz_4.jpg -> barszcz czerwony\n",
            "sernik z rodzynkami_3.jpg -> sernik\n",
            "zupa z grzybami_11.jpg -> zupa grzybowa\n",
            "super bigos_15.jpg -> bigos\n",
            "ciasto makowe_9.jpg -> makowiec\n",
            "polskie pierogi_24.jpg -> pierogi\n",
            "sernik z rodzynkami_15.jpg -> pierogi\n",
            "zupa z grzybami_1.jpg -> zupa grzybowa\n",
            "polskie pierogi_5.jpg -> pierogi\n",
            "sernik z rodzynkami_1.jpg -> sernik\n",
            "sernik z rodzynkami_12.jpg -> sernik\n",
            "polskie pierogi_25.jpg -> bigos\n",
            "ciasto makowe_1.jpg -> makowiec\n",
            "zupa z grzybami_14.jpg -> zupa grzybowa\n",
            "super bigos_1.jpg -> bigos\n",
            "zupa z grzybami_17.jpg -> zupa grzybowa\n",
            "sernik z rodzynkami_2.jpg -> sernik\n",
            "polskie pierogi_18.jpg -> pierogi\n",
            "sernik z rodzynkami_17.jpg -> sernik\n",
            "ciasto makowe_15.jpg -> sernik\n",
            "zupa barszcz_12.jpg -> barszcz czerwony\n",
            "ciasto makowe_13.jpg -> makowiec\n",
            "super bigos_10.jpg -> bigos\n",
            "ciasto makowe_7.jpg -> makowiec\n",
            "zupa barszcz_6.jpg -> barszcz czerwony\n",
            "zupa z grzybami_9.jpg -> zupa grzybowa\n",
            "zupa z grzybami_15.jpg -> zupa grzybowa\n",
            "ciasto makowe_10.jpg -> sernik\n",
            "zupa barszcz_19.jpg -> barszcz czerwony\n",
            "zupa barszcz_1.jpg -> barszcz czerwony\n",
            "zupa barszcz_15.jpg -> barszcz czerwony\n",
            "sernik z rodzynkami_13.jpg -> sernik\n",
            "super bigos_21.jpg -> bigos\n",
            "polskie pierogi_19.jpg -> pierogi\n",
            "zupa barszcz_7.jpg -> barszcz czerwony\n",
            "sernik z rodzynkami_5.jpg -> sernik\n",
            "super bigos_9.jpg -> bigos\n",
            "polskie pierogi_9.jpg -> pierogi\n",
            "super bigos_13.jpg -> bigos\n",
            "zupa z grzybami_16.jpg -> zupa grzybowa\n",
            "polskie pierogi_13.jpg -> pierogi\n",
            "polskie pierogi_2.jpg -> pierogi\n",
            "zupa barszcz_5.jpg -> bigos\n",
            "ciasto makowe_20.jpg -> sernik\n",
            "super bigos_2.jpg -> bigos\n",
            "polskie pierogi_14.jpg -> pierogi\n",
            "sernik z rodzynkami_14.jpg -> sernik\n",
            "ciasto makowe_11.jpg -> sernik\n",
            "polskie pierogi_4.jpg -> pierogi\n",
            "polskie pierogi_7.jpg -> pierogi\n",
            "super bigos_8.jpg -> bigos\n",
            "zupa barszcz_10.jpg -> barszcz czerwony\n"
          ]
        }
      ]
    }
  ]
}